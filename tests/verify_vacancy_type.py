#!/usr/bin/env python3
"""
Script para verificar la variedad de tipos de vacante que el scraper
puede extraer de una b√∫squeda general en Dubl√≠n.
"""
import asyncio
import sys
import os
import logging
from collections import Counter

# A√±adir el directorio ra√≠z al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s: %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("verify_vacancy")

# Importar el scraper
from src.scrapers.scraper_educationposts import EducationPosts

# Condado de Dublin
COUNTY_ID = "27"
COUNTY_NAME = "Dublin"

async def verify_vacancy_types_in_dublin():
    """
    Verifica la variedad de tipos de vacante extra√≠dos en una b√∫squeda general en Dubl√≠n.
    """
    logger.info(f"üîç VERIFICANDO VARIEDAD DE TIPOS DE VACANTE EN {COUNTY_NAME.upper()}")
    logger.info("=" * 70)
    
    try:
        # Crear un scraper para una b√∫squeda general en Dubl√≠n (sin filtro de tipo de vacante)
        scraper = EducationPosts(
            level="primary", 
            county_id=COUNTY_ID,
            vacancy_type="", # Sin filtro de tipo de vacante
            max_workers=3,
            max_pages=2  # Analizar las primeras 2 p√°ginas para tener una buena muestra
        )
        
        # Ejecutar b√∫squeda
        offers = await scraper.fetch_all()
        
        if not offers:
            logger.warning(f"‚ÑπÔ∏è No se encontraron ofertas en {COUNTY_NAME} en este momento.")
            return

        logger.info(f"Se encontraron {len(offers)} ofertas en total. Analizando las primeras 10 para verificar la variedad...")
        offers_to_check = offers[:10]

        all_vacancy_types = []
        for offer in offers_to_check:
            all_vacancy_types.append(offer.get("vacancy", "Desconocido"))

        # Contar la frecuencia de cada tipo de vacante
        type_counts = Counter(all_vacancy_types)

        # Resumen final
        logger.info("\n" + "=" * 70)
        logger.info("üìä RESUMEN DE TIPOS DE VACANTE ENCONTRADOS")
        logger.info("=" * 70)
        
        if not type_counts:
            logger.warning("No se pudo extraer ning√∫n tipo de vacante.")
            return

        logger.info(f"Se encontraron {len(type_counts)} tipos de vacante √∫nicos:")
        for tipo, cantidad in type_counts.items():
            logger.info(f"  ‚Ä¢ '{tipo}': {cantidad} veces")

        # Conclusi√≥n
        if len(type_counts) > 1:
            logger.info("\n‚úÖ ¬°√âxito! El scraper est√° extrayendo una variedad de tipos de vacante y no los agrupa todos en uno solo.")
        else:
            logger.warning("\n‚ö†Ô∏è El scraper solo encontr√≥ un tipo de vacante. Esto podr√≠a ser correcto si solo hay un tipo de oferta disponible, o podr√≠a indicar un problema si se esperaba m√°s variedad.")

    except Exception as e:
        logger.error(f"‚ùå Ocurri√≥ un error durante la verificaci√≥n: {str(e)}")

if __name__ == "__main__":
    asyncio.run(verify_vacancy_types_in_dublin()) 